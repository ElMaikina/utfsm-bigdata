\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Despligue del cluster}{4}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Implementación del tutorial}{4}{subsection.1.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{code/ssh_into_master.sh}{{1}{4}{Conectarse por primera vez al Master usando la llave PEM con la IP publica}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}{\ignorespaces Conectarse por primera vez al Master usando la llave PEM con la IP publica}}{4}{lstlisting.1}\protected@file@percent }
\newlabel{code/update.sh}{{2}{5}{Actualizar repositorios locales y descargar actualizaciones}{lstlisting.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}{\ignorespaces Actualizar repositorios locales y descargar actualizaciones}}{5}{lstlisting.2}\protected@file@percent }
\newlabel{code/install_java.sh}{{3}{5}{Descargar Java / OpenJDK 11 usando APT}{lstlisting.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}{\ignorespaces Descargar Java / OpenJDK 11 usando APT}}{5}{lstlisting.3}\protected@file@percent }
\newlabel{code/create_pub_key.sh}{{4}{5}{Crear una llave publica en formato RSA y autorizarla}{lstlisting.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}{\ignorespaces Crear una llave publica en formato RSA y autorizarla}}{5}{lstlisting.4}\protected@file@percent }
\newlabel{code/download_hadoop.sh}{{5}{5}{Descargar y descomprimir Hadoop en el Master}{lstlisting.5}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}{\ignorespaces Descargar y descomprimir Hadoop en el Master}}{5}{lstlisting.5}\protected@file@percent }
\newlabel{code/edit_env_vars.sh}{{6}{5}{Editar las Variables de Entorno usando el usuario Root y el editor de texto Vim}{lstlisting.6}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {6}{\ignorespaces Editar las Variables de Entorno usando el usuario Root y el editor de texto Vim}}{5}{lstlisting.6}\protected@file@percent }
\newlabel{code/env_vars.sh}{{7}{6}{Variables de Entorno que usaremos para el cluster}{lstlisting.7}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7}{\ignorespaces Variables de Entorno que usaremos para el cluster}}{6}{lstlisting.7}\protected@file@percent }
\newlabel{code/core-site.xml}{{8}{7}{hadoop-3.3.6/etc/hadoop/core-site.xml}{lstlisting.8}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {8}{\ignorespaces hadoop-3.3.6/etc/hadoop/core-site.xml}}{7}{lstlisting.8}\protected@file@percent }
\newlabel{code/hdfs-site.xml}{{9}{7}{hadoop-3.3.6/etc/hadoop/hdfs-site.xml}{lstlisting.9}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {9}{\ignorespaces hadoop-3.3.6/etc/hadoop/hdfs-site.xml}}{7}{lstlisting.9}\protected@file@percent }
\newlabel{code/mapred-site.xml}{{10}{8}{hadoop-3.3.6/etc/hadoop/mapred-site.xml}{lstlisting.10}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {10}{\ignorespaces hadoop-3.3.6/etc/hadoop/mapred-site.xml}}{8}{lstlisting.10}\protected@file@percent }
\newlabel{code/yarn-site.xml}{{11}{9}{hadoop-3.3.6/etc/hadoop/yarn-site.xml}{lstlisting.11}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {11}{\ignorespaces hadoop-3.3.6/etc/hadoop/yarn-site.xml}}{9}{lstlisting.11}\protected@file@percent }
\newlabel{code/worker_priv_ip.sh}{{12}{10}{IP's privadas de los Workers en la carpeta Home del Master}{lstlisting.12}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {12}{\ignorespaces IP's privadas de los Workers en la carpeta Home del Master}}{10}{lstlisting.12}\protected@file@percent }
\newlabel{code/arch_hadoop.sh}{{13}{10}{Borrar el archivo hadoop-3.3.6.tar.gz y comprimimos el directorio hadoop-3.3.6}{lstlisting.13}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {13}{\ignorespaces Borrar el archivo hadoop-3.3.6.tar.gz y comprimimos el directorio hadoop-3.3.6}}{10}{lstlisting.13}\protected@file@percent }
\newlabel{code/install1.sh}{{14}{11}{Script para configurar todos los Workers desde el Master}{lstlisting.14}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {14}{\ignorespaces Script para configurar todos los Workers desde el Master}}{11}{lstlisting.14}\protected@file@percent }
\newlabel{code/install2.sh}{{15}{12}{Script para configurar todos los Workers desde el Master}{lstlisting.15}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {15}{\ignorespaces Script para configurar todos los Workers desde el Master}}{12}{lstlisting.15}\protected@file@percent }
\newlabel{code/init_cluster.sh}{{16}{13}{Formateamos el File System, lo iniciamos y llamamos al negociador de recursos YARN}{lstlisting.16}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {16}{\ignorespaces Formateamos el File System, lo iniciamos y llamamos al negociador de recursos YARN}}{13}{lstlisting.16}\protected@file@percent }
\newlabel{code/hdfs-blocks1.sh}{{17}{13}{Corroborar estado de nuestro HDFS}{lstlisting.17}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {17}{\ignorespaces Corroborar estado de nuestro HDFS}}{13}{lstlisting.17}\protected@file@percent }
\newlabel{code/hdfs-blocks2.sh}{{18}{13}{Estado del HDFS luego de haber ejecutado un Map Reduce}{lstlisting.18}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {18}{\ignorespaces Estado del HDFS luego de haber ejecutado un Map Reduce}}{13}{lstlisting.18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Captura de pantalla de la ``AWS Management Console - EC2'' que muestra las máquinas del cluster creado con el tutorial}}{14}{figure.caption.29}\protected@file@percent }
\newlabel{5-creacion_de_worker-3.PNG}{{1}{14}{Captura de pantalla de la ``AWS Management Console - EC2'' que muestra las máquinas del cluster creado con el tutorial}{figure.caption.29}{}}
\newlabel{code/exec_map_reduce.sh}{{19}{14}{Ejecutar el Map Reduce y leer su salida}{lstlisting.19}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {19}{\ignorespaces Ejecutar el Map Reduce y leer su salida}}{14}{lstlisting.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Expansión del cluster}{15}{subsection.1.2}\protected@file@percent }
\newlabel{code/expand_to_8.sh}{{20}{15}{Los archivos que hay que modificar antes de ejecutar el script de instalacion nuevamente}{lstlisting.20}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {20}{\ignorespaces Los archivos que hay que modificar antes de ejecutar el script de instalacion nuevamente}}{15}{lstlisting.20}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Captura de pantalla de la ``AWS Management Console - EC2'' que muestra las máquinas del cluster expandido}}{16}{figure.caption.31}\protected@file@percent }
\newlabel{expanded_cluster_ec2}{{2}{16}{Captura de pantalla de la ``AWS Management Console - EC2'' que muestra las máquinas del cluster expandido}{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Cliente web}{16}{subsection.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Captura de pantalla del cliente web de Hadoop}}{17}{figure.caption.32}\protected@file@percent }
\newlabel{hadoop.PNG}{{3}{17}{Captura de pantalla del cliente web de Hadoop}{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Captura de pantalla del cliente web de HDFS}}{17}{figure.caption.33}\protected@file@percent }
\newlabel{hdfs.PNG}{{4}{17}{Captura de pantalla del cliente web de HDFS}{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Instancias mejoradas para no sufrir}}{18}{figure.caption.34}\protected@file@percent }
\newlabel{9-mejorar_los_nodos.png}{{5}{18}{Instancias mejoradas para no sufrir}{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Instalación de Apache Hive}{18}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Procedimiento}{18}{subsection.2.1}\protected@file@percent }
\newlabel{code/down-hive.sh}{{21}{18}{Usar WGET para descargar Apache Hive 4.0.1}{lstlisting.21}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {21}{\ignorespaces Usar WGET para descargar Apache Hive 4.0.1}}{18}{lstlisting.21}\protected@file@percent }
\newlabel{code/untar-hive.sh}{{22}{18}{Descomprimimos la carpeta de Apache Hive 4.0.1}{lstlisting.22}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {22}{\ignorespaces Descomprimimos la carpeta de Apache Hive 4.0.1}}{18}{lstlisting.22}\protected@file@percent }
\newlabel{code/hive-site.xml}{{23}{19}{Archivo de configuracion de Apache Hive}{lstlisting.23}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {23}{\ignorespaces Archivo de configuracion de Apache Hive}}{19}{lstlisting.23}\protected@file@percent }
\newlabel{code/metastore-n-hiveserver2.sh}{{24}{19}{Levantar MetaStore y HiveServer2}{lstlisting.24}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {24}{\ignorespaces Levantar MetaStore y HiveServer2}}{19}{lstlisting.24}\protected@file@percent }
\newlabel{code/beeline.sh}{{25}{20}{Usar Beeline como interfaz a Hive}{lstlisting.25}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {25}{\ignorespaces Usar Beeline como interfaz a Hive}}{20}{lstlisting.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Prueba}{21}{subsection.2.2}\protected@file@percent }
\newlabel{lst:004}{{26}{21}{Ejemplo de uso de Apache Hive}{lstlisting.26}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {26}{\ignorespaces Ejemplo de uso de Apache Hive}}{21}{lstlisting.26}\protected@file@percent }
\newlabel{code/hive-output-1.sh}{{27}{22}{Salida de Apache Hive (Parte 1)}{lstlisting.27}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {27}{\ignorespaces Salida de Apache Hive (Parte 1)}}{22}{lstlisting.27}\protected@file@percent }
\newlabel{code/hive-output-2.sh}{{28}{23}{Salida de Apache Hive (Parte 2)}{lstlisting.28}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {28}{\ignorespaces Salida de Apache Hive (Parte 2)}}{23}{lstlisting.28}\protected@file@percent }
\newlabel{code/hive-output-3.sh}{{29}{24}{Salida de Apache Hive (Parte 3)}{lstlisting.29}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {29}{\ignorespaces Salida de Apache Hive (Parte 3)}}{24}{lstlisting.29}\protected@file@percent }
\newlabel{code/hive-output-4.sh}{{30}{25}{Salida de Apache Hive (Parte 4)}{lstlisting.30}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {30}{\ignorespaces Salida de Apache Hive (Parte 4)}}{25}{lstlisting.30}\protected@file@percent }
\newlabel{code/hive-output-5.sh}{{31}{26}{Salida de Apache Hive (Parte 5)}{lstlisting.31}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {31}{\ignorespaces Salida de Apache Hive (Parte 5)}}{26}{lstlisting.31}\protected@file@percent }
\newlabel{code/hive-output-6.sh}{{32}{27}{Salida de Apache Hive (Parte 6)}{lstlisting.32}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {32}{\ignorespaces Salida de Apache Hive (Parte 6)}}{27}{lstlisting.32}\protected@file@percent }
\newlabel{code/hive-output-7.sh}{{33}{28}{Salida de Apache Hive (Parte 7)}{lstlisting.33}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {33}{\ignorespaces Salida de Apache Hive (Parte 7)}}{28}{lstlisting.33}\protected@file@percent }
\newlabel{lst:005}{{34}{28}{Resultado esperado para ejemplo de uso de Apache Hive}{lstlisting.34}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {34}{\ignorespaces Resultado esperado para ejemplo de uso de Apache Hive}}{28}{lstlisting.34}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Exploración del HDFS}{29}{section.3}\protected@file@percent }
\newlabel{lst:006}{{35}{29}{Ejemplo de uso de Apache Hive}{lstlisting.35}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {35}{\ignorespaces Ejemplo de uso de Apache Hive}}{29}{lstlisting.35}\protected@file@percent }
\newlabel{code/hive-print-rep.sh}{{36}{29}{Muestra el archivo, los bloques que ocupa, el factor de replicacion y la ubicacion de cada bloque}{lstlisting.36}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {36}{\ignorespaces Muestra el archivo, los bloques que ocupa, el factor de replicacion y la ubicacion de cada bloque}}{29}{lstlisting.36}\protected@file@percent }
\newlabel{code/aws-cli.sh}{{37}{30}{Instalar AWS CLI}{lstlisting.37}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {37}{\ignorespaces Instalar AWS CLI}}{30}{lstlisting.37}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Uso del cluster}{31}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Importación}{31}{subsection.4.1}\protected@file@percent }
\newlabel{importacion.sh}{{38}{31}{Importacion de los datos sucios}{lstlisting.38}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {38}{\ignorespaces Importacion de los datos sucios}}{31}{lstlisting.38}\protected@file@percent }
\newlabel{importacion.hql}{{39}{32}{Importacion de los datos sucios}{lstlisting.39}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {39}{\ignorespaces Importacion de los datos sucios}}{32}{lstlisting.39}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Parsing}{33}{subsection.4.2}\protected@file@percent }
\newlabel{cleanup.py}{{40}{33}{Limpieza de los datos sucios}{lstlisting.40}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {40}{\ignorespaces Limpieza de los datos sucios}}{33}{lstlisting.40}\protected@file@percent }
\newlabel{importacion_limpia.hql}{{41}{33}{Importacion de los datos sucios}{lstlisting.41}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {41}{\ignorespaces Importacion de los datos sucios}}{33}{lstlisting.41}\protected@file@percent }
\newlabel{output.hql}{{42}{34}{Analisis de los datos limpios para entender que significa cada columna}{lstlisting.42}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {42}{\ignorespaces Analisis de los datos limpios para entender que significa cada columna}}{34}{lstlisting.42}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Análisis}{35}{subsection.4.3}\protected@file@percent }
\newlabel{obs_limpias_1.hql}{{43}{35}{Observacion con nombres y tipos correctos}{lstlisting.43}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {43}{\ignorespaces Observacion con nombres y tipos correctos}}{35}{lstlisting.43}\protected@file@percent }
\expandafter\ifx\csname c@table@totc\endcsname\relax\newcounter{table@totc}\fi\setcounter{table@totc}{0}
\expandafter\ifx\csname c@figure@totc\endcsname\relax\newcounter{figure@totc}\fi\setcounter{figure@totc}{5}
\expandafter\ifx\csname c@lstlisting@totc\endcsname\relax\newcounter{lstlisting@totc}\fi\setcounter{lstlisting@totc}{44}
\newlabel{obs_limpias_2.hql}{{44}{36}{Observacion con nombres y tipos correctos}{lstlisting.44}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {44}{\ignorespaces Observacion con nombres y tipos correctos}}{36}{lstlisting.44}\protected@file@percent }
\gdef \@abspage@last{36}
