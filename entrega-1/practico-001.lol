\contentsline {lstlisting}{\numberline {1}{\ignorespaces Conectarse por primera vez al Master usando la llave PEM con la IP publica}}{5}{lstlisting.1}%
\contentsline {lstlisting}{\numberline {2}{\ignorespaces Actualizar repositorios locales y descargar actualizaciones}}{5}{lstlisting.2}%
\contentsline {lstlisting}{\numberline {3}{\ignorespaces Descargar Java / OpenJDK 11 usando APT}}{6}{lstlisting.3}%
\contentsline {lstlisting}{\numberline {4}{\ignorespaces Crear una llave publica en formato RSA y autorizarla}}{6}{lstlisting.4}%
\contentsline {lstlisting}{\numberline {5}{\ignorespaces Descargar y descomprimir Hadoop en el Master}}{6}{lstlisting.5}%
\contentsline {lstlisting}{\numberline {6}{\ignorespaces Editar las Variables de Entorno usando el usuario Root y el editor de texto Vim}}{6}{lstlisting.6}%
\contentsline {lstlisting}{\numberline {7}{\ignorespaces Variables de Entorno que usaremos para el cluster}}{6}{lstlisting.7}%
\contentsline {lstlisting}{\numberline {8}{\ignorespaces hadoop-3.3.6/etc/hadoop/core-site.xml}}{7}{lstlisting.8}%
\contentsline {lstlisting}{\numberline {9}{\ignorespaces hadoop-3.3.6/etc/hadoop/hdfs-site.xml}}{7}{lstlisting.9}%
\contentsline {lstlisting}{\numberline {10}{\ignorespaces hadoop-3.3.6/etc/hadoop/mapred-site.xml}}{8}{lstlisting.10}%
\contentsline {lstlisting}{\numberline {11}{\ignorespaces hadoop-3.3.6/etc/hadoop/yarn-site.xml}}{9}{lstlisting.11}%
\contentsline {lstlisting}{\numberline {12}{\ignorespaces IP's privadas de los Workers en la carpeta Home del Master}}{10}{lstlisting.12}%
\contentsline {lstlisting}{\numberline {13}{\ignorespaces Borrar el archivo hadoop-3.3.6.tar.gz y comprimimos el directorio hadoop-3.3.6}}{10}{lstlisting.13}%
\contentsline {lstlisting}{\numberline {14}{\ignorespaces Script para configurar todos los Workers desde el Master}}{11}{lstlisting.14}%
\contentsline {lstlisting}{\numberline {15}{\ignorespaces Script para configurar todos los Workers desde el Master}}{12}{lstlisting.15}%
\contentsline {lstlisting}{\numberline {16}{\ignorespaces Formateamos el File System, lo iniciamos y llamamos al negociador de recursos YARN}}{13}{lstlisting.16}%
\contentsline {lstlisting}{\numberline {17}{\ignorespaces Corroborar estado de nuestro HDFS}}{13}{lstlisting.17}%
\contentsline {lstlisting}{\numberline {18}{\ignorespaces Estado del HDFS luego de haber ejecutado un Map Reduce}}{13}{lstlisting.18}%
\contentsline {lstlisting}{\numberline {19}{\ignorespaces Ejecutar el Map Reduce y leer su salida}}{14}{lstlisting.19}%
\contentsline {lstlisting}{\numberline {20}{\ignorespaces Los archivos que hay que modificar antes de ejecutar el script de instalacion nuevamente}}{15}{lstlisting.20}%
\contentsline {lstlisting}{\numberline {21}{\ignorespaces Código utilizado en la expansión del cluster}}{15}{lstlisting.21}%
\contentsline {lstlisting}{\numberline {22}{\ignorespaces Ejemplo de uso de Apache Hive}}{18}{lstlisting.22}%
\contentsline {lstlisting}{\numberline {23}{\ignorespaces Resultado esperado para ejemplo de uso de Apache Hive {\color {red} Algunos de los valores han sido alterados, deben ser corregidos con el resultado de su procedimiento.}}}{19}{lstlisting.23}%
\contentsline {lstlisting}{\numberline {24}{\ignorespaces Ejemplo de uso de Apache Hive}}{19}{lstlisting.24}%
\contentsline {lstlisting}{\numberline {25}{\ignorespaces Script de reporte de DFS}}{19}{lstlisting.25}%
