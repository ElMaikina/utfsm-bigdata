\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Despligue del cluster}{5}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Implementación del tutorial}{5}{subsection.1.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{code/ssh_into_master.sh}{{1}{5}{Conectarse por primera vez al Master usando la llave PEM con la IP publica}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}{\ignorespaces Conectarse por primera vez al Master usando la llave PEM con la IP publica}}{5}{lstlisting.1}\protected@file@percent }
\newlabel{code/update.sh}{{2}{5}{Actualizar repositorios locales y descargar actualizaciones}{lstlisting.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}{\ignorespaces Actualizar repositorios locales y descargar actualizaciones}}{5}{lstlisting.2}\protected@file@percent }
\newlabel{code/install_java.sh}{{3}{6}{Descargar Java / OpenJDK 11 usando APT}{lstlisting.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}{\ignorespaces Descargar Java / OpenJDK 11 usando APT}}{6}{lstlisting.3}\protected@file@percent }
\newlabel{code/create_pub_key.sh}{{4}{6}{Crear una llave publica en formato RSA y autorizarla}{lstlisting.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}{\ignorespaces Crear una llave publica en formato RSA y autorizarla}}{6}{lstlisting.4}\protected@file@percent }
\newlabel{code/download_hadoop.sh}{{5}{6}{Descargar y descomprimir Hadoop en el Master}{lstlisting.5}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}{\ignorespaces Descargar y descomprimir Hadoop en el Master}}{6}{lstlisting.5}\protected@file@percent }
\newlabel{code/edit_env_vars.sh}{{6}{6}{Editar las Variables de Entorno usando el usuario Root y el editor de texto Vim}{lstlisting.6}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {6}{\ignorespaces Editar las Variables de Entorno usando el usuario Root y el editor de texto Vim}}{6}{lstlisting.6}\protected@file@percent }
\newlabel{code/env_vars.sh}{{7}{6}{Variables de Entorno que usaremos para el cluster}{lstlisting.7}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7}{\ignorespaces Variables de Entorno que usaremos para el cluster}}{6}{lstlisting.7}\protected@file@percent }
\newlabel{code/core-site.xml}{{8}{7}{hadoop-3.3.6/etc/hadoop/core-site.xml}{lstlisting.8}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {8}{\ignorespaces hadoop-3.3.6/etc/hadoop/core-site.xml}}{7}{lstlisting.8}\protected@file@percent }
\newlabel{code/hdfs-site.xml}{{9}{7}{hadoop-3.3.6/etc/hadoop/hdfs-site.xml}{lstlisting.9}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {9}{\ignorespaces hadoop-3.3.6/etc/hadoop/hdfs-site.xml}}{7}{lstlisting.9}\protected@file@percent }
\newlabel{code/mapred-site.xml}{{10}{8}{hadoop-3.3.6/etc/hadoop/mapred-site.xml}{lstlisting.10}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {10}{\ignorespaces hadoop-3.3.6/etc/hadoop/mapred-site.xml}}{8}{lstlisting.10}\protected@file@percent }
\newlabel{code/yarn-site.xml}{{11}{9}{hadoop-3.3.6/etc/hadoop/yarn-site.xml}{lstlisting.11}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {11}{\ignorespaces hadoop-3.3.6/etc/hadoop/yarn-site.xml}}{9}{lstlisting.11}\protected@file@percent }
\newlabel{code/worker_priv_ip.sh}{{12}{10}{IP's privadas de los Workers en la carpeta Home del Master}{lstlisting.12}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {12}{\ignorespaces IP's privadas de los Workers en la carpeta Home del Master}}{10}{lstlisting.12}\protected@file@percent }
\newlabel{code/arch_hadoop.sh}{{13}{10}{Borrar el archivo hadoop-3.3.6.tar.gz y comprimimos el directorio hadoop-3.3.6}{lstlisting.13}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {13}{\ignorespaces Borrar el archivo hadoop-3.3.6.tar.gz y comprimimos el directorio hadoop-3.3.6}}{10}{lstlisting.13}\protected@file@percent }
\newlabel{code/install1.sh}{{14}{11}{Script para configurar todos los Workers desde el Master}{lstlisting.14}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {14}{\ignorespaces Script para configurar todos los Workers desde el Master}}{11}{lstlisting.14}\protected@file@percent }
\newlabel{code/install2.sh}{{15}{12}{Script para configurar todos los Workers desde el Master}{lstlisting.15}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {15}{\ignorespaces Script para configurar todos los Workers desde el Master}}{12}{lstlisting.15}\protected@file@percent }
\newlabel{code/init_cluster.sh}{{16}{13}{Formateamos el File System, lo iniciamos y llamamos al negociador de recursos YARN}{lstlisting.16}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {16}{\ignorespaces Formateamos el File System, lo iniciamos y llamamos al negociador de recursos YARN}}{13}{lstlisting.16}\protected@file@percent }
\newlabel{code/hdfs-blocks1.sh}{{17}{13}{Corroborar estado de nuestro HDFS}{lstlisting.17}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {17}{\ignorespaces Corroborar estado de nuestro HDFS}}{13}{lstlisting.17}\protected@file@percent }
\newlabel{code/hdfs-blocks2.sh}{{18}{13}{Estado del HDFS luego de haber ejecutado un Map Reduce}{lstlisting.18}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {18}{\ignorespaces Estado del HDFS luego de haber ejecutado un Map Reduce}}{13}{lstlisting.18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Captura de pantalla de la ``AWS Management Console - EC2'' que muestra las máquinas del cluster creado con el tutorial}}{14}{figure.caption.29}\protected@file@percent }
\newlabel{5-creacion_de_worker-3.PNG}{{1}{14}{Captura de pantalla de la ``AWS Management Console - EC2'' que muestra las máquinas del cluster creado con el tutorial}{figure.caption.29}{}}
\newlabel{code/exec_map_reduce.sh}{{19}{14}{Ejecutar el Map Reduce y leer su salida}{lstlisting.19}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {19}{\ignorespaces Ejecutar el Map Reduce y leer su salida}}{14}{lstlisting.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Expansión del cluster}{15}{subsection.1.2}\protected@file@percent }
\newlabel{code/expand_to_8.sh}{{20}{15}{Los archivos que hay que modificar antes de ejecutar el script de instalacion nuevamente}{lstlisting.20}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {20}{\ignorespaces Los archivos que hay que modificar antes de ejecutar el script de instalacion nuevamente}}{15}{lstlisting.20}\protected@file@percent }
\newlabel{lst:002}{{21}{15}{Código utilizado en la expansión del cluster}{lstlisting.21}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {21}{\ignorespaces Código utilizado en la expansión del cluster}}{15}{lstlisting.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Cliente web}{15}{subsection.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Captura de pantalla de la ``AWS Management Console - EC2'' que muestra las máquinas del cluster expandido}}{16}{figure.caption.32}\protected@file@percent }
\newlabel{expanded_cluster_ec2}{{2}{16}{Captura de pantalla de la ``AWS Management Console - EC2'' que muestra las máquinas del cluster expandido}{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Captura de pantalla del cliente web de Hadoop}}{16}{figure.caption.33}\protected@file@percent }
\newlabel{hadoop.PNG}{{3}{16}{Captura de pantalla del cliente web de Hadoop}{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Captura de pantalla del cliente web de HDFS}}{17}{figure.caption.34}\protected@file@percent }
\newlabel{hdfs.PNG}{{4}{17}{Captura de pantalla del cliente web de HDFS}{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Instalación de Apache Hive}{18}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Procedimiento}{18}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Prueba}{18}{subsection.2.2}\protected@file@percent }
\newlabel{lst:004}{{22}{18}{Ejemplo de uso de Apache Hive}{lstlisting.22}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {22}{\ignorespaces Ejemplo de uso de Apache Hive}}{18}{lstlisting.22}\protected@file@percent }
\newlabel{lst:005}{{23}{19}{Resultado esperado para ejemplo de uso de Apache Hive {\color {red} Algunos de los valores han sido alterados, deben ser corregidos con el resultado de su procedimiento.}}{lstlisting.23}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {23}{\ignorespaces Resultado esperado para ejemplo de uso de Apache Hive {\color  {red} Algunos de los valores han sido alterados, deben ser corregidos con el resultado de su procedimiento.}}}{19}{lstlisting.23}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Exploración del HDFS}{19}{section.3}\protected@file@percent }
\newlabel{lst:006}{{24}{19}{Ejemplo de uso de Apache Hive}{lstlisting.24}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {24}{\ignorespaces Ejemplo de uso de Apache Hive}}{19}{lstlisting.24}\protected@file@percent }
\newlabel{lst:007}{{25}{19}{Script de reporte de DFS}{lstlisting.25}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {25}{\ignorespaces Script de reporte de DFS}}{19}{lstlisting.25}\protected@file@percent }
\expandafter\ifx\csname c@table@totc\endcsname\relax\newcounter{table@totc}\fi\setcounter{table@totc}{0}
\expandafter\ifx\csname c@figure@totc\endcsname\relax\newcounter{figure@totc}\fi\setcounter{figure@totc}{4}
\expandafter\ifx\csname c@lstlisting@totc\endcsname\relax\newcounter{lstlisting@totc}\fi\setcounter{lstlisting@totc}{25}
\@writefile{toc}{\contentsline {section}{\numberline {4}Uso del cluster}{20}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Importación}{20}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Parsing}{20}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Análisis}{20}{subsection.4.3}\protected@file@percent }
\gdef \@abspage@last{20}
